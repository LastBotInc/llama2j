<component name="ProjectRunConfigurationManager">
  <configuration default="false" name="CUDA Llama-2-7b-chat.bin 4-GPU" type="Application" factoryName="Application">
    <envs>
      <env name="CUDA_HOME" value="/usr/local/cuda/" />
      <env name="CUDA_DEVICE_MAX_CONNECTIONS" value="16" />
    </envs>
    <option name="MAIN_CLASS_NAME" value="com.lastbot.llama2j.Run" />
    <module name="llama2j" />
    <option name="PROGRAM_PARAMETERS" value="--mode CUDA --checkpoint Llama-2-7b-chat.bin --gpuMem &quot;17,24,24,24&quot;" />
    <option name="VM_PARAMETERS" value="-Xmx32g -XX:+UnlockExperimentalVMOptions -XX:+UseZGC" />
    <method v="2">
      <option name="Make" enabled="true" />
    </method>
  </configuration>
</component>